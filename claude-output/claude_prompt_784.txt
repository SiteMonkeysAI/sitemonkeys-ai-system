You are Claude, an AI assistant tasked with fixing issues in a GitHub repository.

Issue #784: [claude-fix] CRITICAL: Hunt Down "I encountered a technical issue" Ghost Error ‚Äî Context Reaches AI But Response Fails

Issue Description:
# üî¥ CRITICAL: Hunt Down "I encountered a technical issue" Ghost Error ‚Äî Context Reaches AI But Response Fails

## Evidence From Live Smoke Test (Feb 16, 2026)

Live runtime logs PROVE that all pipelines are delivering data correctly. Memory retrieves, documents load, external data fetches ‚Äî context reaches GPT-4. But certain queries still return this generic error:

> "I encountered a technical issue processing your request. I want to be honest: rather than provide potentially incorrect information, I need to acknowledge this limitation. Could you try rephrasing your question or breaking it into smaller parts?"

### Queries That SUCCEEDED (same session, same pipelines):
- "What is my favorite color?" ‚Üí ‚úÖ AI answered correctly using memory
- "What is the project budget?" ‚Üí ‚úÖ AI answered "$75,000" from uploaded document
- "What's the current price of gold?" ‚Üí ‚úÖ External lookup worked, AI answered
- "Most recent news related to Colombia?" ‚Üí ‚úÖ External lookup worked, AI answered
- "Latest information on Greenland?" ‚Üí ‚úÖ External lookup worked, AI answered

### Queries That FAILED (same session, same pipelines):
- "Can you explain what that document is about?" ‚Üí ‚ùå Generic error (document was loaded: 731 tokens ‚úÖ, memory loaded ‚úÖ)
- "Can you analyze that document?" ‚Üí ‚ùå Generic error (same document loaded ‚úÖ)
- "What's the newest information involving President Trump?" ‚Üí ‚ùå Generic error (external lookup succeeded: 781 chars ‚úÖ, memory loaded ‚úÖ)
- "Current medal count in Winter Olympics?" ‚Üí ‚ùå Generic error (external lookup succeeded: 693 chars ‚úÖ, memory loaded ‚úÖ)

### The Pattern
The pipelines are NOT broken. Something AFTER context injection is failing on certain queries and triggering a catch-all error response. The data reaches the AI ‚Äî the error happens during or after the AI call.

---

## Investigation Philosophy

> Same rules as Issue #781 ‚Äî this is neurosurgery.

1. **DO NOT stop at the first error handler you find.** There may be multiple catch blocks that produce this message. Find ALL of them.
2. **Trace the COMPLETE path** from the AI API call through response processing, personality application, enforcement, validation, and back to the user ‚Äî for BOTH successful and failed queries.
3. **Cross-reference against the Bible.** Every component in the response path must behave as specified.
4. **Production-grade fixes only.** No placeholders, no bandaids.
5. **Zero regression.** The queries that currently work MUST continue working.
6. **Even after finding what appears to be the root cause, keep looking.** There may be multiple failure modes producing the same error message.

---

## üîç INVESTIGATION AREA 1: Find Every Instance of the Error Message

### Step 1: Search the entire codebase

Search for ALL occurrences of:
- `"I encountered a technical issue"`
- `"technical issue processing"`
- `"try rephrasing your question"`
- `"breaking it into smaller parts"`
- Any template or function that generates this message

### What to document:
- [ ] **1.1** ‚Äî Every file:line that contains or generates this error message
- [ ] **1.2** ‚Äî For each occurrence: what catch block or condition triggers it?
- [ ] **1.3** ‚Äî For each occurrence: what is the ACTUAL error being caught? Is it logged anywhere, or is it swallowed silently?
- [ ] **1.4** ‚Äî Is this message hardcoded in multiple places, or generated by a single error handler function?

---

## üîç INVESTIGATION AREA 2: Trace the Failed Request Path

### Use the Trump query as the test case

The logs show this sequence for "What's the newest information involving President Trump?":
```
‚úÖ server ‚Üí orchestrator
‚úÖ Memory retrieved: 11 memories, semantic method
‚úÖ Document loaded: Truth_Clean_RECON_FORENSIC_REPORT... (731 tokens)
‚úÖ Context assembly: Memory 2497t ‚úÖ, Documents 731t ‚úÖ
‚úÖ External lookup: Google News RSS, 781 chars extracted
‚úÖ External lookup successful: 1 source, 807 chars
‚úÖ Phase 4 injected external context: 781 chars
‚úÖ orchestrator ‚Üí reasoning
‚úÖ reasoning ‚Üí enforcement
[NO FURTHER HANDOFF LOGS ‚Äî what happened next?]
‚Üí User received: "I encountered a technical issue..."
```

### What to investigate:
- [ ] **2.1** ‚Äî After `reasoning ‚Üí enforcement`, what is the next step? Trace the code path from enforcement through to AI API call for this specific flow.
- [ ] **2.2** ‚Äî Was the AI API actually called? Check for any GPT-4 or Claude API call logs for this request. If the API was called, what did it return? If it wasn't called, what prevented it?
- [ ] **2.3** ‚Äî If the API was called and returned a response, what post-processing happens? Trace through personality application (Eli/Roxy), response validation, enforcement checks, truth-first validation.
- [ ] **2.4** ‚Äî At which exact step does the error get triggered? Add temporary diagnostic logging at EVERY step between enforcement and user response to find the exact failure point.
- [ ] **2.5** ‚Äî Is the error a JavaScript exception (thrown error caught by try/catch) or a logical condition (code deliberately returning the error message)?

---

## üîç INVESTIGATION AREA 3: Compare Successful vs Failed Requests

### Why did "Colombia news" succeed but "Trump headlines" fail?

Both queries:
- Retrieved memories ‚úÖ
- Had documents loaded ‚úÖ  
- Got external data from Google News RSS ‚úÖ
- Had context assembled and injected ‚úÖ

### What to investigate:
- [ ] **3.1** ‚Äî Compare the total token counts between successful and failed queries. Is there a token threshold being exceeded? (Failed queries may have more total context.)
- [ ] **3.2** ‚Äî Compare the content of external data. Does the Trump/Olympics response contain content that triggers a content filter, political guardrail, or enforcement rule?
- [ ] **3.3** ‚Äî Check the political guardrails system. The Bible specifies political neutrality enforcement. Is the Trump query triggering `politicalGuardrails.js` or similar enforcement that rejects the response?
- [ ] **3.4** ‚Äî Check the document analysis queries. When the user asks "analyze that document" referring to the forensic report, is something in the document content (legal terms, personal information, device serial numbers) triggering a safety filter or content validator?
- [ ] **3.5** ‚Äî Check GPT-4's max_tokens setting. The logs show `max_tokens: 2000` for GPT-4 responses. If the AI tries to generate a response longer than 2000 tokens (likely for document analysis or news summary), does the truncation or timeout trigger the error?
- [ ] **3.6** ‚Äî Check for API timeout. Complex queries with large context may take longer. Is there a timeout that kills the request and returns the generic error?

---

## üîç INVESTIGATION AREA 4: The Response Processing Pipeline

### After GPT-4/Claude returns a response, what happens to it?

Per the Bible, the response goes through:
```
AI raw response
‚Üí Truth-first validation (confidence scoring, hallucination check)
‚Üí Personality application (Eli or Roxy tone/style)
‚Üí Enforcement checks (political guardrails, product validation, mode linting)
‚Üí Response formatting
‚Üí Return to user
```

### What to investigate:
- [ ] **4.1** ‚Äî Does the truth-first validator ever REJECT a response and substitute the error message? If confidence is too low, does it bail out with the generic error instead of returning the low-confidence response with appropriate disclaimers?
- [ ] **4.2** ‚Äî Does the personality system (Eli/Roxy) ever fail to process a response? If the personality application throws an error, does it cascade to the generic error message?
- [ ] **4.3** ‚Äî Do the enforcement checks ever reject a response entirely? Check each validator: assumptions.js, politicalGuardrails.js, productValidation.js, modeLinter.js. Could any of these be rejecting valid responses?
- [ ] **4.4** ‚Äî Is there an error in the response formatting step? If the AI returns valid content but formatting fails, does that trigger the error?
- [ ] **4.5** ‚Äî Check the Eli/Roxy confidence threshold logic. The logs show `[ELI] Eli: Low confidence (0.53) but external lookup succeeded - no disclaimer needed` for successful queries. For failed queries, is confidence even lower and triggering a rejection?

---

## üîç INVESTIGATION AREA 5: Token and Context Budget

### The forensic report document adds 731 tokens to every query after upload

- [ ] **5.1** ‚Äî What is the total context window being sent to GPT-4? Add up: system prompt + memory context + document context + external data + user query + conversation history. For failed queries, is this exceeding GPT-4's input limit?
- [ ] **5.2** ‚Äî The logs show `Total message content: 28191 chars` for the Winter Olympics query. At ~4 chars per token, that's ~7000 tokens of input. With max_tokens: 2000 for output, total is ~9000. Is this within GPT-4's limits?
- [ ] **5.3** ‚Äî Check `#enforceTokenBudget()`. Does it silently drop critical context when the budget is exceeded? Could it be dropping the user's actual question while keeping memory and documents?
- [ ] **5.4** ‚Äî Is conversation history accumulating? Each successive query in the session adds history. Are later queries failing because accumulated history pushes the context over limits?

---

## üîç INVESTIGATION AREA 6: Additional Anomaly ‚Äî Memory Token Count Always 0

### Every memory retrieval log shows `Total tokens: 0` even when memories are found

```
[HANDOFF:MEMORY-RETRIEVAL‚ÜíFORMAT] Retrieved 18 memories from DB
[HANDOFF:MEMORY-RETRIEVAL‚ÜíFORMAT] Total tokens: 0    ‚Üê This is wrong
```

- [ ] **6.1** ‚Äî Find where `result.tokens` is set during memory retrieval. It's always 0, which means either the token count isn't being calculated, or it's stored in a different field name than what the log reads.
- [ ] **6.2** ‚Äî Does this affect the token budget calculation? If the system thinks memory is 0 tokens, it won't enforce memory token limits correctly, potentially allowing memory to consume the entire budget and crowd out other context.
- [ ] **6.3** ‚Äî Fix the token count so it reflects actual memory size. This is not just a logging issue ‚Äî if token budgeting relies on this number, incorrect values cause cascading problems.

---

## üîß Fix Standards

### Same as Issue #781 ‚Äî Non-Negotiable:

- **ES6 modules only** (import/export, no require())
- **Standard error pattern**: try/catch returning { success: boolean, data/error }
- **All database queries must include user_id filtering**
- **All async functions must handle timeouts and failures gracefully**
- **Logging at every handoff point** in the response processing pipeline (not just the request pipeline ‚Äî we now need visibility into what happens AFTER the AI responds)
- **Zero regression**: Queries that currently succeed MUST continue succeeding
- **Align with the Bible**: Every fix must match the specification documents

### What the fix must NOT do:
- ‚ùå Do NOT remove or weaken any truth-first validation
- ‚ùå Do NOT remove political guardrails or enforcement
- ‚ùå Do NOT increase token limits without understanding the cost impact
- ‚ùå Do NOT replace the error message with a different generic message ‚Äî fix the ROOT CAUSE
- ‚ùå Do NOT suppress errors silently ‚Äî if something fails, log the ACTUAL error before returning the user-facing message

### What the fix SHOULD do:
- ‚úÖ Log the ACTUAL error/exception that triggers the generic message (currently being swallowed)
- ‚úÖ Identify which specific post-processing step fails for each query type
- ‚úÖ Fix the root cause so the AI's valid response reaches the user
- ‚úÖ Add diagnostic logging to the RESPONSE pipeline (we now have request pipeline logging from PR #782 ‚Äî we need the other half)
- ‚úÖ Fix the memory token count anomaly (Area 6)

---

## üìã Investigation Checklist

- [ ] All instances of the error message found (Area 1)
- [ ] Failed request path fully traced with evidence (Area 2)
- [ ] Successful vs failed comparison completed (Area 3)
- [ ] Response processing pipeline fully investigated (Area 4)
- [ ] Token budget analysis completed (Area 5)
- [ ] Memory token count anomaly investigated (Area 6)
- [ ] Root cause identified with file:line evidence
- [ ] Fix implemented and tested
- [ ] Previously successful queries verified still working
- [ ] Diagnostic logging added to response pipeline

---

## üìö Reference: The Bible

- **Engineering Specifications** ‚Äî orchestrator processRequest flow, response validation
- **Technical Standards** ‚Äî error handling patterns, API response format
- **File 3: Intelligence & Personality Framework** ‚Äî Eli/Roxy response generation
- **File 6: Personality, Intelligence, and Alignment System** ‚Äî enforcement chain
- **File 7: Recommendation Integrity and Enforcement System** ‚Äî validation rules
- **File 9: Mode Enforcement System** ‚Äî mode-specific response handling
- **File 10: Political, Truth, and Product Integrity Rules** ‚Äî political guardrails

---

*The pipelines work. The data reaches the AI. Something in the response path is killing valid responses and replacing them with a generic error. Find it, log the real error, fix the root cause.*
Your task is to:
1. Analyze the issue carefully to understand the problem
2. Look through the repository to identify the relevant files that need to be modified
3. Make precise changes to fix the issue
4. Use the Edit tool to modify files directly when needed
5. Be minimal in your changes - only modify what's necessary to fix the issue

After making changes, provide a summary of what you did in this format:

---SUMMARY---
[Your detailed summary of changes, including which files were modified and how]
---END SUMMARY---

Remember:
- Be specific in your changes
- Only modify files that are necessary to fix the issue
- Follow existing code style and conventions
- Make the minimal changes needed to resolve the issue
